{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÇ **Loading Data**\n",
    "\n",
    "Preparing your data for an LLM involves an ingestion pipeline similar to ML data cleaning or traditional ETL processes.\n",
    "\n",
    "### **Ingestion Pipeline Stages**\n",
    "  - üì• Load the data\n",
    "  - üîß Transform the data\n",
    "  - üóÉÔ∏è Index and store the data\n",
    "\n",
    "\n",
    "Let's start by downloading some example files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Base URL for Project Gutenberg texts\n",
    "base_url = \"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt\"\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "directory = Path(\"../data\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate a list of book IDs to download\n",
    "book_ids = range(1, 11)  # This will create a range from 1 to 10\n",
    "\n",
    "# Generate URLs for each book ID\n",
    "urls = [base_url.format(book_id=book_id) for book_id in book_ids]\n",
    "\n",
    "# Download each file and save it in the specified directory\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the filename from the URL using the book ID and create a file name\n",
    "        book_id = url.split('/')[-2]  # Extracts the book ID from the URL\n",
    "        filename = f\"pg{book_id}.txt\"\n",
    "        file_path = directory / filename\n",
    "        # Save the file to the specified directory\n",
    "        file_path.write_text(response.text)\n",
    "        print(f\"Downloaded {filename} to {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}. HTTP status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì• Load the data\n",
    "\n",
    "To use data with an LLM, first load it using data connectors, known as `Readers` in LlamaIndex, which format data into `Document` objects containing data and metadata.\n",
    "\n",
    "üìö **SimpleDirectoryReader**:\n",
    "  - The most straightforward loader is `SimpleDirectoryReader``.\n",
    "  - Built into LlamaIndex, it reads various formats (Markdown, PDFs, Word documents, PowerPoint decks, images, audio, video) from every file in a directory, creating documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd  /workspaces/hands-on-ai-rag-using-llamaindex-3830207/02_Fundamental_Concepts_in_LlamaIndex\n",
      "DIR\n",
      " ['02_04_Indexing.ipynb', '02_07_Agents.ipynb', '02_02_Using_LLMs.ipynb', '02_01_How_LlamaIndex_Is_Organized.ipynb', '02_05_Storing.ipynb', '02_03_Loading_Data.ipynb', '02_06_Querying.ipynb']\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.legacy.readers.file.base import SimpleDirectoryReader\n",
    "import os\n",
    "\n",
    "print(\"pwd \", os.getcwd())\n",
    "print(\"DIR\\n\",os.listdir())\n",
    "# documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "# /workspaces/hands-on-ai-rag-using-llamaindex-3830207/data/almanack_of_naval_ravikant.pdf\n",
    "documents = SimpleDirectoryReader(input_files=['../data/almanack_of_naval_ravikant.pdf']).load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.legacy.schema.Document"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': 'fede48c1-5fcb-425d-bdc6-ad8fef497b5f',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '4',\n",
       "  'file_name': 'almanack_of_naval_ravikant.pdf',\n",
       "  'file_path': '../data/almanack_of_naval_ravikant.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 1884309,\n",
       "  'creation_date': '2025-01-23',\n",
       "  'last_modified_date': '2025-01-23',\n",
       "  'last_accessed_date': '2025-01-23'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {},\n",
       " 'text': 'Copyright ¬© 2020 EriC JorgEnson\\nAll rights reserved.\\nthE AlmAn ACk of nA vAl rA vikAnt\\nA Guide to Wealth and Happiness\\nisBn 978-1-5445-1422-2 Hardcover\\n 978-1-5445-1421-5 Paperback\\n 978-1-5445-1420-8 Ebook\\nThis book has been created as a public service. It is available for \\nfree download in pdf and e-reader versions on Navalmanack.com. \\nNaval is not earning any money on this book. Naval has essays, \\npodcasts and more at Nav.al and is on Twitter @Naval.',\n",
       " 'start_char_idx': None,\n",
       " 'end_char_idx': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_seperator': '\\n'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually Create Document Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "manual_document = Document(text=\"This is an example of a manual document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '772eab16-991b-49f8-af60-b499d42add4d',\n",
       " 'embedding': None,\n",
       " 'metadata': {},\n",
       " 'excluded_embed_metadata_keys': [],\n",
       " 'excluded_llm_metadata_keys': [],\n",
       " 'relationships': {},\n",
       " 'text': 'This is an example of a manual document',\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': None,\n",
       " 'end_char_idx': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_seperator': '\\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_document.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding metadata\n",
    "\n",
    "You can add metadata in the document constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_document_with_metadata = Document(\n",
    "    text=\"This is an example of a manual document\",\n",
    "    metadata={\"filename\": \"made-up-file-name\", \"category\": \"imaginary-category\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '374d4814-df31-4a63-9cde-42d299cf6a8d',\n",
       " 'embedding': None,\n",
       " 'metadata': {'filename': 'made-up-file-name',\n",
       "  'category': 'imaginary-category'},\n",
       " 'excluded_embed_metadata_keys': [],\n",
       " 'excluded_llm_metadata_keys': [],\n",
       " 'relationships': {},\n",
       " 'text': 'This is an example of a manual document',\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': None,\n",
       " 'end_char_idx': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_seperator': '\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_document_with_metadata.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or after the document is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_document.metadata={\"filename\": \"made-up-file-name\", \"category\": \"imaginary-category\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '772eab16-991b-49f8-af60-b499d42add4d',\n",
       " 'embedding': None,\n",
       " 'metadata': {'filename': 'made-up-file-name',\n",
       "  'category': 'imaginary-category'},\n",
       " 'excluded_embed_metadata_keys': [],\n",
       " 'excluded_llm_metadata_keys': [],\n",
       " 'relationships': {},\n",
       " 'text': 'This is an example of a manual document',\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': None,\n",
       " 'end_char_idx': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_seperator': '\\n'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_document.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Transform the data\n",
    "\n",
    "After loading, we must process and transform data for retrieval. We need to transform the list of `Document` objects into `Node` objects \n",
    "\n",
    "- ‚úÇÔ∏è Include chunking, extracting metadata, and embedding each chunk in transformations.\n",
    "\n",
    "- üåü Nodes are a first-class citizen in LlamaIndex, allowing direct definition or parsing from Documents.\n",
    "\n",
    "- üîÑ Transformation inputs and outputs are `Node` objects (Note: `Document` is subclass of `Node`).\n",
    "\n",
    "- üõ†Ô∏è Nodes are \"chunks\" of Documents, including text, images, etc., plus metadata and relationships.\n",
    "\n",
    "- üìä `NodeParser` classes convert Documents into Nodes with all necessary attributes. There are [a number of](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules.html) `NodeParser`'s you can choose from!\n",
    "\n",
    "- üìë High-level API: Use `.from_documents()` for automatic parsing and chunking of Document objects.\n",
    "\n",
    "- üîç Underlying process splits Document into Node objects, maintaining text and metadata with a link to their parent Document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2502c557668b4e2ea928d4c29cd1a69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown document type: <class 'llama_index.legacy.schema.Document'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter\n\u001b[1;32m      3\u001b[0m parser \u001b[38;5;241m=\u001b[39m SentenceSplitter(\n\u001b[1;32m      4\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \u001b[38;5;66;03m# in tokens\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, \u001b[38;5;66;03m#in tokens\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     paragraph_separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/llama_index/core/node_parser/interface.py:146\u001b[0m, in \u001b[0;36mNodeParser.get_nodes_from_documents\u001b[0;34m(self, documents, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m doc_id_to_document \u001b[38;5;241m=\u001b[39m {doc\u001b[38;5;241m.\u001b[39mid_: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    144\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mNODE_PARSING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mDOCUMENTS: documents}\n\u001b[1;32m    145\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m--> 146\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_parsed_nodes(nodes, doc_id_to_document)\n\u001b[1;32m    149\u001b[0m     event\u001b[38;5;241m.\u001b[39mon_end({EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes})\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/llama_index/core/node_parser/interface.py:246\u001b[0m, in \u001b[0;36mMetadataAwareTextSplitter._parse_nodes\u001b[0;34m(self, nodes, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     metadata_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_str(node)\n\u001b[1;32m    241\u001b[0m     splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_text_metadata_aware(\n\u001b[1;32m    242\u001b[0m         node\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mNONE),\n\u001b[1;32m    243\u001b[0m         metadata_str\u001b[38;5;241m=\u001b[39mmetadata_str,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m     all_nodes\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 246\u001b[0m         \u001b[43mbuild_nodes_from_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_nodes\n",
      "File \u001b[0;32m/opt/conda/envs/lil_llama_index/lib/python3.10/site-packages/llama_index/core/node_parser/node_utils.py:91\u001b[0m, in \u001b[0;36mbuild_nodes_from_splits\u001b[0;34m(text_splits, document, ref_doc, id_func)\u001b[0m\n\u001b[1;32m     89\u001b[0m         nodes\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown document type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(document)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown document type: <class 'llama_index.legacy.schema.Document'>"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "parser = SentenceSplitter(\n",
    "    chunk_size=128, # in tokens\n",
    "    chunk_overlap=16, #in tokens\n",
    "    paragraph_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nodes[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[42].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose to construct Node objects manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "\n",
    "node1 = TextNode(text=\"Dad is married to Mom\", id_=\"001\")\n",
    "\n",
    "node2 = TextNode(text=\"Dad is Son's dad\", id_=\"002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NodeRelationships\n",
    "\n",
    "You can set relationships between nodes.\n",
    "\n",
    "- üåê NodeRelationships assign connections between chunks of text. It's useful for:\n",
    "  - Documents organized in a hierarchical manner (e.g., book, chapter, section, subsection)\n",
    "  - Maintaining sequential order\n",
    "  - Other complex relationships (ie, in legal documents for links a clause or other cases) \n",
    "\n",
    "- üîç NodeRelationships help retrieve not just the relevant section, but also related sections that might provide additional context or information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n",
    "    node_id=node2.node_id\n",
    ")\n",
    "\n",
    "node2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n",
    "    node_id=node1.node_id\n",
    ")\n",
    "nodes = [node1, node2]\n",
    "\n",
    "node2.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n",
    "    node_id=node1.node_id, metadata={\"Romie\": \"Mom\", \"Harpreet\": \"Dad\", \"Jind\":\"Daughter\", \"Jugaad\":\"Son\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of clean up, let's just go ahead and delete the text files we downloaded since we won't need them going forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
